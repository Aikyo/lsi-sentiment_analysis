{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "train = pd.read_csv('labeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "pre = pd.read_csv('testData.tsv', header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess file \n",
    "label = train['sentiment']\n",
    "train_data = []\n",
    "pre_data = []\n",
    "for i in range(len(train['review'])):\n",
    "    train_data.append(BeautifulSoup(train['review'][i], \"html.parser\").get_text())\n",
    "test_data = []\n",
    "for i in range(len(pre['review'])):\n",
    "    pre_data.append(BeautifulSoup(pre['review'][i], \"html.parser\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(pre_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 合并训练和测试集以便进行TFIDF向量化操作\n",
    "data_all = train_data + pre_data\n",
    "len_train = len(train_data)\n",
    "print(len_train)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'them', 'have', 'on', 'they', 'am', 'up', 'aren', 'wouldn', 'didn', 'while', 'few', 'own', \"wasn't\", 'it', 'itself', \"should've\", 'most', \"you'll\", 'hasn', 'before', 'myself', 'wasn', 'hadn', 'doesn', 'there', 'couldn', 'his', 'he', 'off', 's', \"needn't\", 'did', 'are', \"you'd\", 'nor', 'is', 'once', 'yourselves', 'o', \"aren't\", 'how', 'who', 'out', 'further', 'or', 'more', 'yours', 'because', \"shan't\", 'i', 'me', 'about', 'under', 'against', 'm', 'themselves', 'down', \"hasn't\", 'over', 'where', 'herself', 'had', 'has', 'as', 'to', 'shan', 'until', 'below', 'y', \"haven't\", 'some', 'our', \"that'll\", 'but', 'which', 'why', \"mightn't\", 'does', 'should', 'now', 'above', 'such', \"shouldn't\", 'with', 'than', 'a', 'haven', 'here', \"you're\", \"didn't\", 'all', 'having', 'my', 'when', 'so', 'weren', 'in', 'himself', 'hers', 'mustn', 'shouldn', 'this', 'during', 'any', \"couldn't\", 'been', 'each', 'very', \"don't\", 'its', 'only', 'their', \"weren't\", 'ain', 'will', \"mustn't\", 'she', 'him', 'by', 'your', 'you', 'into', \"she's\", \"it's\", 'if', 'we', \"hadn't\", 'ours', 'just', \"isn't\", 'then', 'that', 'needn', 'theirs', 'be', 't', 'won', 'again', 'can', 'd', 'don', 're', \"doesn't\", 'same', 'whom', 'isn', 'after', 'what', 'mightn', 'the', 'ourselves', 'no', 'll', 'ma', 'of', 'not', 'too', 'were', 'her', 'was', 'and', 'yourself', 'doing', \"won't\", 'an', 'both', 'at', 'through', 'those', 'between', 'other', 'being', \"you've\", 'do', 'for', 'these', 've', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#英文停止词，set()集合函数消除重复项\n",
    "list_stopWords = list(set(stopwords.words('english')))\n",
    "print(list_stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# bow 模型    \n",
    "import re\n",
    "#lower后，去除非 azAZ开头的单词\n",
    "# [[word,word,........]]\n",
    "texts = [[word for word in re.sub(\"[^a-zA-Z]\", \" \", doc.lower()).split() if word != \"\" and word not in list_stopWords] for doc in data_all]\n",
    "\"\"\"\n",
    "token2id : dict of (str, int)\n",
    "    token -> tokenId.\n",
    "id2token : dict of (int, str)\n",
    "\"\"\"\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "#corpus [ [(wordid:frequency),] ]\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf_model = models.TfidfModel(corpus=corpus, id2word=dictionary, normalize=True) \n",
    "#把所有的文档转化成tf-idf \n",
    "#转化后的文档是一个稀疏矩阵，这时采用密集矩阵来表示的话，会造成极大的内存浪费，\n",
    "#所以gensim内部是用稀疏矩阵的形式来表示\n",
    "corpus_tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len8 :81 -- len9 :22 \n"
     ]
    }
   ],
   "source": [
    "#每个句子长度不一，\n",
    "#倘若使用密集矩阵的话是一样的长度\n",
    "len8 = len(corpus_tfidf[8])#\n",
    "len9 = len(corpus_tfidf[9])\n",
    "print(\"len8 :{0} -- len9 :{1} \".format(len8,len9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lsi 主题模型，作为特征向量\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=200)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "\n",
    "# 提取数字，转化为numpy的矩阵\n",
    "all_x = [[v for k,v in doc] for doc in corpus_lsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_lsi[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.163*\"movie\"'), (1, '-0.302*\"bad\"'), (2, '-0.665*\"show\"')]\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(corpus_lsi))\n",
    "# (50000, 200, 2)\n",
    "#三个主题每个主题用一个word\n",
    "print(lsi_model.print_topics(3,1))\n",
    "\n",
    "#lsi_model.print_topics(2)\n",
    "# print(corpus_lsi[0])\n",
    "\n",
    "# import numpy as np\n",
    "# print(np.shape(all_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "knn算法 10折交叉验证得分: \n",
      " [0.82179872 0.81945952 0.83272512 0.82310144 0.829504   0.82556576\n",
      " 0.81654688 0.82681824 0.8256928  0.81336256]\n",
      "\n",
      "knn算法 10折交叉验证平均得分: \n",
      " 0.823457504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(all_x[:len_train], label)\n",
    "\n",
    "scores = cross_val_score(knn_model, all_x[:len_train], label, cv=10, scoring='roc_auc')\n",
    "print(\"\\nknn 10折交叉验证得分: \\n\", scores)\n",
    "print(\"\\nknn 10折交叉验证平均得分: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " logistic regression 10折交叉验证得分: \n",
      " [0.93431744 0.9281536  0.9413472  0.93139584 0.93204096 0.93203136\n",
      " 0.9335392  0.94093824 0.9232384  0.9319104 ]\n",
      "\n",
      " logistic regression 10折交叉验证平均得分: \n",
      " 0.932891264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_model = LogisticRegression(C=0.1, max_iter=100)\n",
    "lr_model.fit(all_x[:len_train], label)\n",
    "\n",
    "scores = cross_val_score(lr_model, all_x[:len_train], label, cv=10, scoring='roc_auc')\n",
    "print(\"\\n logistic regression 10折交叉验证得分: \\n\", scores)\n",
    "print(\"\\n logistic regression 10折交叉验证平均得分: \\n\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForest 10折交叉验证得分: \n",
      " [0.90736832 0.9032128  0.91823424 0.90634624 0.90518336 0.9027776\n",
      " 0.90534528 0.90977024 0.89864448 0.90629312]\n",
      "\n",
      " RandomForest 10折交叉验证平均得分: \n",
      " 0.9063175680000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=0)\n",
    "rf_model.fit(all_x[:len_train], label)\n",
    "\n",
    "scores = cross_val_score(rf_model, all_x[:len_train], label, cv=10, scoring='roc_auc')\n",
    "print(\"\\n RandomForest 10折交叉验证得分: \\n\", scores)\n",
    "print(\"\\n RandomForest 10折交叉验证平均得分: \\n\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB 10折交叉验证得分: \n",
      " [0.93912832 0.93999936 0.94611776 0.93853504 0.93499392 0.93230208\n",
      " 0.93981824 0.94093696 0.92940416 0.93759104]\n",
      "\n",
      "XGB 10折交叉验证平均得分: \n",
      " 0.9378826879999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=150, min_samples_leaf=3, max_depth=6)\n",
    "\"\"\"\n",
    "AttributeError: 'list' object has no attribute 'shape'\n",
    "list => np.array\n",
    "\"\"\"\n",
    "xgb_model.fit(np.array(all_x[:len_train]), label)\n",
    "\n",
    "scores = cross_val_score(xgb_model, np.array(all_x[:len_train]), label, cv=10, scoring='roc_auc')\n",
    "print(\"\\nXGB 10折交叉验证得分: \\n\", scores)\n",
    "print(\"\\nXGB 10折交叉验证平均得分: \\n\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
